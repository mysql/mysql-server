include/group_replication.inc
Warnings:
Note	####	Sending passwords in plain text without SSL/TLS is extremely insecure.
Note	####	Storing MySQL user name or password information in the master info repository is not secure and is therefore not recommended. Please consider using the USER and PASSWORD connection options for START SLAVE; see the 'START SLAVE Syntax' in the MySQL Manual for more information.
[connection server1]
#
# 1. Install clone plugin on server1.
[connection server1]
INSTALL PLUGIN clone SONAME 'CLONE_PLUGIN';
#
# 2. Set a privileged user for server 1 GR recovery channel
CREATE USER 'u1'@'localhost';
GRANT SESSION_VARIABLES_ADMIN, REPLICATION_APPLIER ON *.* TO 'u1'@'localhost';
GRANT CREATE,INSERT ON *.* TO 'u1'@'localhost';
CHANGE REPLICATION SOURCE TO PRIVILEGE_CHECKS_USER = 'u1'@'localhost' FOR CHANNEL 'group_replication_recovery';
#
# 3. Bootstrap server1 and add some data
include/start_and_bootstrap_group_replication.inc
CREATE DATABASE db1;
CREATE TABLE db1.t1 (c1 INT NOT NULL PRIMARY KEY) ENGINE=InnoDB;
INSERT INTO db1.t1 VALUES (1);
#
# 4. Restart server 2 with a monitoring process (mysqld_safe) if needed
[connection server2]
include/spawn_monitoring_process.inc
#
# 5. Setup the server so group replication starts on boot
#    Install the Clone plugin
INSTALL PLUGIN clone SONAME 'CLONE_PLUGIN';
#
# 6. On a empty server2 start group replication
#    Wait for it to restart and come back
#    Check clone was completed
SET GLOBAL group_replication_clone_threshold= 1;
START GROUP_REPLICATION;
include/rpl_reconnect.inc
include/gr_wait_for_member_state.inc
include/assert.inc [Clone must be completed]
include/diff_tables.inc [server1:db1.t1,server2:db1.t1]
#
# 7. Check that the recovery privileged user was preserved
[connection server1]
include/assert.inc [Credentials on server 1 are preserved]
[connection server2]
include/assert.inc [Credentials on server 2 were proprely cloned]
include/assert.inc [Performance schema values on server 2 are correct]
#
# 8. Cleanup
SET GLOBAL group_replication_clone_threshold= 9223372036854775807;
RESET PERSIST IF EXISTS group_replication_group_name;
RESET PERSIST IF EXISTS group_replication_local_address;
RESET PERSIST IF EXISTS group_replication_group_seeds;
RESET PERSIST IF EXISTS group_replication_start_on_boot;
RESET PERSIST IF EXISTS group_replication_communication_stack;
DROP TABLE db1.t1;
DROP DATABASE db1;
include/rpl_sync.inc
[connection server1]
CHANGE REPLICATION SOURCE TO PRIVILEGE_CHECKS_USER = NULL FOR CHANNEL 'group_replication_recovery';
[connection server2]
CHANGE REPLICATION SOURCE TO PRIVILEGE_CHECKS_USER = NULL FOR CHANNEL 'group_replication_recovery';
[connection server1]
DROP USER u1@localhost;
UNINSTALL PLUGIN clone;
[connection server2]
UNINSTALL PLUGIN clone;
set session sql_log_bin=0;
call mtr.add_suppression("This member will start distributed recovery using clone. It is due to the number of missing transactions being higher than the configured threshold of*");
call mtr.add_suppression("Clone removing all user data for provisioning: Started");
call mtr.add_suppression("Clone removing all user data for provisioning: Finished");
set session sql_log_bin=1;
include/clean_monitoring_process.inc
SET GLOBAL group_replication_start_on_boot= START_ON_BOOT_VALUE;
include/group_replication_end.inc
