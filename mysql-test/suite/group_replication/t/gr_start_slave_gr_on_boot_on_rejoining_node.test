################################################################################
## Test case to verify that asynchronous replication channel starting on boot
## waits till member becomes online.
##
## Test:
## 0. This test requires 3 members.
##    M1 and M2 are connected through GR.
##    M1 connects with M3 through asynchronous replication.
## 1. Start GR on server1 & 2
## 2. Start slave for channel 'ch3_1' between server1(slave) and server3(master)
## 3. Add some data to server3 & server2
## 4. Verify servers are in sync and data is replicated to server1
## 5. Restart server1 with group replication start on boot
## 6. Verify on server1 that member is ONLINE and ch3_1 channel is running
##    but syncing of data gets timeout as applier thread is blocked
## 7. Unblock the blocked IO and applier threads and assert that
##    threads started only after member become ONLINE
## 8. Add more data to t2 on server2 and t1 on server3
## 9. Verify data is replicated to server1 and 2
## 10. Cleanup
################################################################################

--source include/have_debug.inc
--source include/have_debug_sync.inc
--source include/big_test.inc
--source include/have_group_replication_plugin.inc
--let $rpl_skip_group_replication_start= 1
--let $rpl_server_count= 3
--source include/group_replication.inc


--echo
--echo # 1. Start GR on server1 & 2

# Boostrap start GR on server2 (Primary)
--let $rpl_connection_name= server2
--source include/rpl_connection.inc
--source include/start_and_bootstrap_group_replication.inc

# Start GR on server1 (Secondary)
--let $rpl_connection_name= server1
--source include/rpl_connection.inc

SET @@GLOBAL.DEBUG= @debug_save;

--source include/start_group_replication.inc

--echo
--echo # 2. Start slave for channel 'ch3_1' between server1(slave) and server3(master)
--replace_result $SERVER_MYPORT_3 SERVER_3_PORT
--eval CHANGE MASTER TO MASTER_HOST='localhost', MASTER_USER='root', MASTER_PORT=$SERVER_MYPORT_3 for channel 'ch3_1'

--let $rpl_channel_name='ch3_1'
--source include/start_slave.inc


--echo
--echo # 3. Add some data to server3 & server2

# server3: create table t1 and add data
--let $rpl_connection_name= server3
--source include/rpl_connection.inc
CREATE TABLE test.t1 (c1 INT NOT NULL PRIMARY KEY) ENGINE=InnoDB;
INSERT INTO test.t1 VALUES (1);

# server2: create table t2 and add data
--let $rpl_connection_name= server2
--source include/rpl_connection.inc
CREATE TABLE test.t2 (c1 INT NOT NULL PRIMARY KEY) ENGINE=InnoDB;
INSERT INTO test.t2 VALUES (1);


--echo
--echo # 4. Verify servers are in sync and data is replicated to server1

# Sync slave(server1) with master(server3)
--let $rpl_connection_name= server3
--source include/rpl_connection.inc
--let $sync_slave_connection=server1
--source include/sync_slave_sql_with_master.inc

# Wait for all servers to be in sync
--source include/rpl_sync.inc

--let $rpl_connection_name= server1
--source include/rpl_connection.inc

--let $assert_text= Verify two tables (t1 & t2) are present in test database
--let $assert_cond= "[SELECT count(table_name) COUNT FROM INFORMATION_SCHEMA.TABLES WHERE table_schema = \'test\', COUNT, 1]" = "2"
--source include/assert.inc

--let $assert_text= Verify test.t2 is synced
--let $assert_cond= "[SELECT count(*) COUNT FROM test.t2, COUNT, 1]" = "1"
--source include/assert.inc


--echo
--echo # 5. Restart server1 with group replication start on boot
--let $rpl_connection_name= server1
--source include/rpl_connection.inc

--let $allow_rpl_inited=1
--let $_group_replication_local_address= `SELECT @@GLOBAL.group_replication_local_address`
--let $_group_replication_group_seeds= `SELECT @@GLOBAL.group_replication_group_seeds`

--let $restart_parameters=restart:--group_replication_local_address=$_group_replication_local_address --group_replication_group_seeds=$_group_replication_group_seeds --group_replication_start_on_boot=1 --group-replication-group-name=$group_replication_group_name --skip-slave-start=0 --log_error_verbosity=3 --log-error=$MYSQLTEST_VARDIR/tmp/gr_start_slave_gr_on_boot_on_rejoining_node.err --loose-debug="d,group_replication_wait_thread_for_server_online"
--replace_result $_group_replication_local_address GROUP_REPLICATION_LOCAL_ADDRESS $_group_replication_group_seeds GROUP_REPLICATION_GROUP_SEEDS $group_replication_group_name GROUP_REPLICATION_GROUP_NAME $MYSQLTEST_VARDIR MYSQLTEST_VARDIR
--source include/restart_mysqld.inc

--let $rpl_server_number= 1
--source include/rpl_reconnect.inc

--echo
--echo # 6. Verify on server1 that member is ONLINE and ch3_1 channel is running
--echo #    but syncing of data gets timeout as applier thread is blocked

--let $group_replication_member_state= ONLINE
--source include/gr_wait_for_member_state.inc

--let $rpl_connection_name= server3
--source include/rpl_connection.inc

INSERT INTO test.t1 VALUES (2);
INSERT INTO test.t1 VALUES (3);

--let $_saved_gtids_server3= `SELECT @@global.gtid_executed`

--let $rpl_connection_name= server1
--source include/rpl_connection.inc

# the gtids are not synced and WAIT_FOR_EXECUTED_GTID_SET gets timedout
--let $assert_text= The gtids are not synced as slave threads are blocked in group replication plugin
--let $assert_cond= `SELECT WAIT_FOR_EXECUTED_GTID_SET('$_saved_gtids_server3', 2) = 1`
--source include/assert.inc


--echo
--echo # 7. Unblock the blocked IO and applier threads and assert that
--echo #    threads started only after member become ONLINE

SET DEBUG_SYNC= "now SIGNAL signal.continue_applier_thread";

--let $rpl_channel_name= 'ch3_1'
--source include/wait_for_slave_to_start.inc

--let $assert_file=$MYSQLTEST_VARDIR/tmp/gr_start_slave_gr_on_boot_on_rejoining_node.err

--let $assert_text= The slave IO thread of channel 'ch3_1' is unblocked as the member is declared ONLINE now
--let $assert_select= The slave IO thread of channel 'ch3_1' is unblocked as the member is declared ONLINE now.
--let $assert_match= The slave IO thread of channel 'ch3_1' is unblocked as the member is declared ONLINE now.*
--source include/assert_grep.inc


--let $assert_text= The slave applier thread of channel 'ch3_1' is unblocked as the member is declared ONLINE now
--let $assert_select= The slave applier thread of channel 'ch3_1' is unblocked as the member is declared ONLINE now.
--let $assert_match= The slave applier thread of channel 'ch3_1' is unblocked as the member is declared ONLINE now.*
--source include/assert_grep.inc


--echo
--echo # 8. Add more data to t2 on server2 and t1 on server3

--let $rpl_connection_name= server2
--source include/rpl_connection.inc

INSERT INTO test.t2 VALUES (2);

--let $rpl_connection_name= server3
--source include/rpl_connection.inc

INSERT INTO test.t1 VALUES (4);


--echo
--echo # 9. Verify data is replicated to server1 and 2

# Sync slave(server1) with master(server3)
--let $rpl_connection_name= server3
--source include/rpl_connection.inc
--let $sync_slave_connection=server1
--source include/sync_slave_sql_with_master.inc

# Wait for all servers to be in sync
--source include/rpl_sync.inc


--let $rpl_connection_name= server2
--source include/rpl_connection.inc

--let $assert_text= Verify test.t1 is synced
--let $assert_cond= "[SELECT count(*) COUNT FROM test.t1, COUNT, 1]" = "4"
--source include/assert.inc

--let $assert_text= Verify test.t2 is synced
--let $assert_cond= "[SELECT count(*) COUNT FROM test.t2, COUNT, 1]" = "2"
--source include/assert.inc

--let $rpl_connection_name= server1
--source include/rpl_connection.inc

--let $assert_text= Verify test.t1 is synced
--let $assert_cond= "[SELECT count(*) COUNT FROM test.t1, COUNT, 1]" = "4"
--source include/assert.inc

--let $assert_text= Verify test.t2 is synced
--let $assert_cond= "[SELECT count(*) COUNT FROM test.t2, COUNT, 1]" = "2"
--source include/assert.inc


--echo
--echo # 10. Clean Up

--let $rpl_connection_name= server2
--source include/rpl_connection.inc
DROP TABLE test.t2;

--let $rpl_connection_name= server1
--source include/rpl_connection.inc

--let $rpl_channel_name='ch3_1'
--source include/stop_slave.inc
--let $rpl_channel_name=

RESET SLAVE ALL FOR CHANNEL 'ch3_1';

DROP TABLE test.t1;

--let $rpl_connection_name= server3
--source include/rpl_connection.inc

DROP TABLE test.t1;

--source include/group_replication_end.inc
