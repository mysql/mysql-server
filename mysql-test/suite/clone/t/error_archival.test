# Test clone with debug sync point to simulate archiving error in different stage

--source include/linux.inc
--source include/have_innodb_16k.inc
--source include/no_valgrind_without_big.inc
--source include/have_debug_sync.inc
--source include/count_sessions.inc

# Needed for the hypergraph optimizer only; since it does not support indexes yet,
# it needs to sort some rows involving fairly large blobs.
set sort_buffer_size=1048576;

call mtr.add_suppression("\\[Warning\\] .*MY-\\d+.* Log writer is waiting for redo-archiver to catch up .*");
call mtr.add_suppression("\\[ERROR\\] .*MY-\\d+.* Log writer waited too long for redo-archiver to advance .*");

--disable_query_log
RESET BINARY LOGS AND GTIDS;
--enable_query_log

## Install plugin
--let $CLONE_DATADIR = $MYSQL_TMP_DIR/data_new

--replace_result $CLONE_PLUGIN CLONE_PLUGIN
--eval INSTALL PLUGIN clone SONAME '$CLONE_PLUGIN'

## Create test schema
--source ../include/create_schema.inc

## Execute Clone while concurrent DMLs are in progress

# Insert 100 rows
call execute_dml(0, 0, 100, 100, 10, 0);

# Check base rows
SHOW CREATE TABLE t1;

SELECT count(*) from t1;
SELECT col1, col2, col3, SUBSTRING(col4, 1000, 32) FROM t1 ORDER BY col1 LIMIT 10;
SELECT col1, col2, col3, SUBSTRING(col4, 1000, 32) FROM t1 ORDER BY col1 DESC LIMIT 10;

SHOW CREATE TABLE t2;
SELECT count(*) from t2;
SELECT col1, col2, col3, SUBSTRING(col4, 1000, 32) FROM t2 ORDER BY col1 LIMIT 10;
SELECT col1, col2, col3, SUBSTRING(col4, 1000, 32) FROM t2 ORDER BY col1 DESC LIMIT 10;

--echo # Test-1: Error during redo archival
--echo # In connection default - Cloning database
SET GLOBAL DEBUG = '+d,clone_redo_archive_error';
SET DEBUG_SYNC = 'clone_file_copy SIGNAL start_dml1 WAIT_FOR resume_clone1';
SET DEBUG_SYNC = 'clone_page_copy SIGNAL start_dml2 WAIT_FOR resume_clone2';
--source ../include/clone_command_send.inc

--echo # In connection con1 - Running Update Random [0 - 100 Key Range]
connect (con1,localhost,root,,);
SET DEBUG_SYNC = 'now WAIT_FOR start_dml1';
START TRANSACTION;
CALL execute_dml(1, 0, 100, 500, 50, 1);
COMMIT;
--echo # Flush all dirty buffers
SET GLOBAL innodb_buf_flush_list_now = 1;
SET DEBUG_SYNC = 'now SIGNAL resume_clone1';

SET DEBUG_SYNC = 'now WAIT_FOR start_dml2';
START TRANSACTION;
CALL execute_dml(1, 0, 100, 300, 50, 1);
COMMIT;
SET DEBUG_SYNC = 'now SIGNAL resume_clone2';

connection default;
--echo # In connection default - Cloning database
--error ER_INTERNAL_ERROR
--reap
--force-rmdir $CLONE_DATADIR
SET GLOBAL DEBUG = '-d,clone_redo_archive_error';
SET DEBUG_SYNC = 'RESET';

--echo # Test-2: Error overwrite redo archival data
--echo # In connection default - Cloning database
SET GLOBAL DEBUG = '+d,clone_redo_no_archive';
SET DEBUG_SYNC = 'clone_file_copy SIGNAL start_dml1 WAIT_FOR resume_clone1';
SET DEBUG_SYNC = 'clone_page_copy SIGNAL start_dml2 WAIT_FOR resume_clone2';
--source ../include/clone_command_send.inc

--echo # In connection con1 - Delete all rows
connection con1;
SET DEBUG_SYNC = 'now WAIT_FOR start_dml1';
START TRANSACTION;
call execute_dml(3, 0, 1, 1, 1, 0);
COMMIT;
--echo # Flush all dirty buffers
SET GLOBAL innodb_buf_flush_list_now = 1;
SET DEBUG_SYNC = 'now SIGNAL resume_clone1';

SET DEBUG_SYNC = 'now WAIT_FOR start_dml2';
--echo # In connection con1 - Insert 200 rows
call execute_dml(0, 0, 200, 200, 10, 0);
SET DEBUG_SYNC = 'now SIGNAL resume_clone2';

connection default;
--echo # In connection default - Cloning database
--error ER_INTERNAL_ERROR
--reap
--force-rmdir $CLONE_DATADIR
SET GLOBAL DEBUG = '-d,clone_redo_no_archive';
SET DEBUG_SYNC = 'RESET';

--echo # Test-3: Successful clone after archival error
--echo # In connection default - Cloning database
SET DEBUG_SYNC = 'clone_file_copy SIGNAL start_dml1 WAIT_FOR resume_clone1';
SET DEBUG_SYNC = 'clone_page_copy SIGNAL start_dml2 WAIT_FOR resume_clone2';
--source ../include/clone_command_send.inc

--echo # In connection con1 - Running Update Random [0 - 100 Key Range]
connection con1;
SET DEBUG_SYNC = 'now WAIT_FOR start_dml1';
START TRANSACTION;
CALL execute_dml(1, 0, 100, 500, 50, 1);
COMMIT;
--echo # Flush all dirty buffers
SET GLOBAL innodb_buf_flush_list_now = 1;
SET DEBUG_SYNC = 'now SIGNAL resume_clone1';

SET DEBUG_SYNC = 'now WAIT_FOR start_dml2';
START TRANSACTION;
CALL execute_dml(1, 0, 100, 300, 50, 1);
COMMIT;
SET DEBUG_SYNC = 'now SIGNAL resume_clone2';

connection default;
--echo # In connection default - Cloning database
--reap
SET DEBUG_SYNC = 'RESET';

disconnect con1;

--echo # Restart cloned database
--replace_result $CLONE_DATADIR CLONE_DATADIR
--let restart_parameters="restart: --datadir=$CLONE_DATADIR"
--source include/restart_mysqld.inc

# Check table in cloned database
SHOW CREATE TABLE t1;
SELECT count(*) from t1;
SELECT col1, col3, SUBSTRING(col4, 1000, 32) FROM t1 ORDER BY col1 LIMIT 10;
SELECT col1, col3, SUBSTRING(col4, 1000, 32) FROM t1 ORDER BY col1 DESC LIMIT 10;

SHOW CREATE TABLE t2;
SELECT count(*) from t2;
SELECT col1, col3, SUBSTRING(col4, 1000, 32) FROM t2 ORDER BY col1 LIMIT 10;
SELECT col1, col3, SUBSTRING(col4, 1000, 32) FROM t2 ORDER BY col1 DESC LIMIT 10;

# Execute procedure to delete all rows and insert
call execute_dml(3, 0, 1, 1, 1, 0);
call execute_dml(0, 0, 100, 100, 10, 0);

SELECT col1, col2, col3, SUBSTRING(col4, 1000, 32) FROM t1 ORDER BY col1 LIMIT 10;
SELECT col1, col2, col3, SUBSTRING(col4, 1000, 32) FROM t1 ORDER BY col1 DESC LIMIT 10;

SELECT col1, col2, col3, SUBSTRING(col4, 1000, 32) FROM t2 ORDER BY col1 LIMIT 10;
SELECT col1, col2, col3, SUBSTRING(col4, 1000, 32) FROM t2 ORDER BY col1 DESC LIMIT 10;

#Cleanup
--let restart_parameters="restart:"
--source include/restart_mysqld.inc

--source ../include/drop_schema.inc

UNINSTALL PLUGIN clone;
SET DEBUG_SYNC = 'RESET';

set sort_buffer_size=DEFAULT;

--source include/wait_until_count_sessions.inc
--force-rmdir $CLONE_DATADIR
