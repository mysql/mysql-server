--source include/have_ndb.inc
--source include/have_binlog_format_mixed_or_row.inc

# Configure replication, don't start applier
--let $rpl_skip_start_slave= 1
--source suite/ndb_rpl/ndb_rpl_init_source_replica.inc

--echo # Generate epoch transactions without dependencies by using WRITESET
--echo # dependency tracking
show variables like 'ndb_log_transaction_dependency';

create table t1 (
  a int primary key,
  b varchar(100),
  c int) engine=ndb;

# Initial row content
insert into t1 values
  (1, "A", 0),
  (2, "A", 0),
  (3, "A", 0);

--echo # Valid state after epoch 0
select * from t1 order by a;

--source include/rpl/connection_replica.inc
--echo # Relevant replica variables
show variables like 'replica_parallel_workers';
show variables like 'log_bin';
show variables like 'log_replica_updates';
show variables like 'replica_preserve_commit_order';

--echo # Supress MTA errors generated by test
call mtr.add_suppression(".*Could not execute Write_rows event.*");
call mtr.add_suppression(".*worker thread retried transaction 1 time.*");
call mtr.add_suppression(".*possibly leaving data in inconsistent state.*");
call mtr.add_suppression(".*worker has stopped after at least one previous worker encountered an error when replica-preserve-commit-order was enabled.*");

--source include/rpl/start_replica.inc

--source include/rpl/connection_source.inc
--source include/rpl/sync_to_replica.inc

--source include/rpl/stop_replica.inc

# Both clusters have same initial 3 rows
# Now define some independent transactions, allowing parallel apply
# but still requiring commit order if specified.

--source include/rpl/connection_source.inc

--echo # Epoch 1
update t1 set b="B", c=1 where a=1;
--source suite/ndb/include/ndb_binlog_wait_own_changes.inc

--echo # Valid state after epoch 1
select * from t1 order by a;

--echo # Epoch 2
begin;
update t1 set b="C", c=2 where a=2;
commit;

--source suite/ndb/include/ndb_binlog_wait_own_changes.inc

--echo # Valid state after epoch 2
select * from t1 order by a;

--echo # Epoch 3
update t1 set b="D", c=3 where a=3;

--source suite/ndb/include/ndb_binlog_wait_own_changes.inc

--echo # Valid state after epoch 3
select * from t1 order by a;

#show binlog events;

--echo # Take a row lock on row 2 on one connection to the replica
--echo # This stops epoch 2 from finishing its prepare, and
--echo # therefore it will be unable to commit.
--echo # With commit ordering on, epoch 3 will not be able to commit
--echo # and will not become visible.

--source include/rpl/connection_replica1.inc

begin;
select * from t1 where a=2 for update;


--echo # Start the replica from the other replica connection
--source include/rpl/connection_replica.inc
--source include/rpl/start_replica.inc

--echo # Row lock should stall epoch 2, and hence also
--echo # the independent epoch 3.
--echo # Check that no sign of epoch 3 can be seen while the
--echo # row lock is held.
--echo # This also stall the replica long enough to fail the transaction
--echo # being applied and thus replication will stop.
let $ct=20;
while ($ct)
{
  if (`select count(1) as c from test.t1 where c=3`)
  {
    --echo FAIL : Epoch 3 committed while Epoch 2 not applicable!
    select * from test.t1 order by a;
    # Will cause result-content mismatch
  }
  sleep 0.5;
  dec $ct;
}

--echo # Expect that only epoch 1 successfully applied.
select * from test.t1 order by a;

--echo # Now cleanup

--source include/rpl/connection_replica1.inc
--echo # Release lock
commit;

--source include/rpl/connection_replica.inc

--echo # Wait for replication error
let $slave_sql_errno= 3030;
--source include/rpl/wait_for_applier_error.inc

--echo # Show the error number after failure
query_vertical
  SELECT LAST_ERROR_NUMBER
    FROM performance_schema.replication_applier_status_by_worker
    WHERE LAST_ERROR_NUMBER != 0;
--echo # Show the coordinator error number and message
--replace_regex /end_log_pos [0-9]*/end_log_pos NNN/ /Worker [0-9]* failed/Worker NNN failed/
query_vertical
  SELECT LAST_ERROR_NUMBER, LAST_ERROR_MESSAGE
    FROM performance_schema.replication_applier_status_by_coordinator;

--echo # Start replication again
--source include/rpl/start_replica.inc

--echo # Resync
--source include/rpl/connection_source.inc
--sync_slave_with_master

--echo # Show resynced
select * from test.t1 order by a;

--source include/rpl/connection_source.inc
--echo # Drop table
drop table test.t1;

--source include/rpl/deinit.inc
