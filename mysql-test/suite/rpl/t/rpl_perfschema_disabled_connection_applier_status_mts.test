#
# ==== Purpose ====
#
# This test asserts that the information regarding the replication timestamps
# is displayed correctly when the system is running with MTS enabled.
#
# ==== Implementation ====
#
# Five transaction types are tested:
#  - create table
#  - insert
#  - update
#  - delete
#  - drop table
# For each statement, the test asserts that the information concerning the
# transaction that is currently being processed matches what is expected
# before and after each of the following replication stages is completed for
# that transaction:
#  1) The connection thread queues the transaction to be processed by the
#     MTS coordinator (table: performance_schema.replication_connection_status)
#  2) The MTS coordinator puts the transaction into a worker's queue
#     (table: performance_schema.replication_applier_status_by_coordinator)
#  3) A worker applies the transaction
#     (table: performance_schema.replication_applier_status_by_worker)
#
# The second part of the test checks if the table
# performance_schema.replication_applier_status_by_worker displays the correct
# information when the slave cannot apply a transaction due to an error.
# Two types of transactions are tested: DDL (DROP table) and DML (insert). After
# the slave fails applying each transaction, the test verifies that
# last_applied_transaction still shows the last transaction applied before the
# failed one, and also that applying_transaction was cleared.
#
# ==== References ====
#
# WL#7374 Performance schema tables to monitor replication lags and queue
# BUG#25694813 INSTRUMENTATION IS ALWAYS ENABLED FOR REPLICATION P_S STATUS
#              TABLES

# the test is binlog-format agnostic
--source include/have_binlog_format_row.inc
--source include/have_debug_sync.inc

--source include/master-slave.inc

--let $is_mts= 1

--source extra/rpl_tests/rpl_ps_connection_applier_status.inc

--source extra/rpl_tests/rpl_ps_connection_applier_status_by_worker_failed_trx.inc

--source include/rpl_end.inc
