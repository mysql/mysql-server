/*****************************************************************************

Copyright (c) 1994, 2023, Oracle and/or its affiliates.

This program is free software; you can redistribute it and/or modify it under
the terms of the GNU General Public License, version 2.0, as published by the
Free Software Foundation.

This program is also distributed with certain software (including but not
limited to OpenSSL) that is licensed under separate terms, as designated in a
particular file or component or in included license documentation. The authors
of MySQL hereby grant you an additional permission to link the program and
your derivative works with the separately licensed software that they have
included with MySQL.

This program is distributed in the hope that it will be useful, but WITHOUT
ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE. See the GNU General Public License, version 2.0,
for more details.

You should have received a copy of the GNU General Public License along with
this program; if not, write to the Free Software Foundation, Inc.,
51 Franklin St, Fifth Floor, Boston, MA 02110-1301  USA

*****************************************************************************/

/** @file include/btr0btr.ic
 The B-tree

 Created 6/2/1994 Heikki Tuuri
 *******************************************************/

#include "mach0data.h"
#ifndef UNIV_HOTBACKUP
#include "mtr0log.h"
#include "mtr0mtr.h"
#include "page0zip.h"
#endif /* !UNIV_HOTBACKUP */

/** NOTE - Changing this from the original number of 50 to 45 as
insert_debug.test was failing in ASAN build because of a stack overflow issue.
It was found that rtr_info_t was taking up a lot of stack space in the function
btr_insert_on_non_leaf_level_func which is part of the recursive stack
trace. */
/** Maximum B-tree page level (not really a hard limit). Used in debug
 assertions in btr_page_set_level and btr_page_get_level */
constexpr uint32_t BTR_MAX_NODE_LEVEL = 45;

#ifndef UNIV_HOTBACKUP
static inline buf_block_t *btr_block_get_func(
    const page_id_t &page_id, const page_size_t &page_size, ulint mode,
    ut::Location location, IF_DEBUG(const dict_index_t *index, ) mtr_t *mtr) {
  buf_block_t *block;

  block = buf_page_get_gen(page_id, page_size, mode, nullptr,
                           Page_fetch::NORMAL, location, mtr);

  if (mode != RW_NO_LATCH) {
    buf_block_dbg_add_level(block, index != nullptr && dict_index_is_ibuf(index)
                                       ? SYNC_IBUF_TREE_NODE
                                       : SYNC_TREE_NODE);
  }

  return (block);
}

/** Sets the index id field of a page. */
static inline void btr_page_set_index_id(
    page_t *page,             /*!< in: page to be created */
    page_zip_des_t *page_zip, /*!< in: compressed page whose uncompressed
                             part will be updated, or NULL */
    space_index_t id,         /*!< in: index id */
    mtr_t *mtr)               /*!< in: mtr */
{
  if (page_zip) {
    mach_write_to_8(page + (PAGE_HEADER + PAGE_INDEX_ID), id);
    page_zip_write_header(page_zip, page + (PAGE_HEADER + PAGE_INDEX_ID), 8,
                          mtr);
  } else {
    mlog_write_ull(page + (PAGE_HEADER + PAGE_INDEX_ID), id, mtr);
  }
}
#endif /* !UNIV_HOTBACKUP */

/** Gets the index id field of a page.
 @return index id */
static inline space_index_t btr_page_get_index_id(
    const page_t *page) /*!< in: index page */
{
  return (mach_read_from_8(page + PAGE_HEADER + PAGE_INDEX_ID));
}

/** Gets the node level field in an index page.
 @param[in] page index page
 @return level, leaf level == 0 */
static inline ulint btr_page_get_level(const page_t *page) {
  ulint level;

  ut_ad(page);

  level = mach_read_from_2(page + PAGE_HEADER + PAGE_LEVEL);

  ut_ad(level <= BTR_MAX_NODE_LEVEL);

  return (level);
}

/** Sets the node level field in an index page. */
static inline void btr_page_set_level(
    page_t *page,             /*!< in: index page */
    page_zip_des_t *page_zip, /*!< in: compressed page whose uncompressed
                             part will be updated, or NULL */
    ulint level,              /*!< in: level, leaf level == 0 */
    mtr_t *mtr)               /*!< in: mini-transaction handle */
{
  ut_ad(page != nullptr);
  ut_ad(mtr != nullptr);
  ut_ad(level <= BTR_MAX_NODE_LEVEL);

  if (page_zip) {
    mach_write_to_2(page + (PAGE_HEADER + PAGE_LEVEL), level);
    page_zip_write_header(page_zip, page + (PAGE_HEADER + PAGE_LEVEL), 2, mtr);
  } else {
    mlog_write_ulint(page + (PAGE_HEADER + PAGE_LEVEL), level, MLOG_2BYTES,
                     mtr);
  }
}

static inline page_no_t btr_page_get_next(const page_t *page,
                                          mtr_t *mtr [[maybe_unused]]) {
  ut_ad(page != nullptr);
  ut_ad(mtr != nullptr);

  return (mach_read_from_4(page + FIL_PAGE_NEXT));
}

/** Sets the next index page field. */
static inline void btr_page_set_next(
    page_t *page,             /*!< in: index page */
    page_zip_des_t *page_zip, /*!< in: compressed page whose uncompressed
                             part will be updated, or NULL */
    page_no_t next,           /*!< in: next page number */
    mtr_t *mtr)               /*!< in: mini-transaction handle */
{
  ut_ad(page != nullptr);
  ut_ad(mtr != nullptr);

  if (page_zip) {
    mach_write_to_4(page + FIL_PAGE_NEXT, next);
    page_zip_write_header(page_zip, page + FIL_PAGE_NEXT, 4, mtr);
  } else {
    mlog_write_ulint(page + FIL_PAGE_NEXT, next, MLOG_4BYTES, mtr);
  }
}

static inline page_no_t btr_page_get_prev(const page_t *page) {
  ut_ad(page != nullptr);
  return (mach_read_from_4(page + FIL_PAGE_PREV));
}

static inline page_no_t btr_page_get_prev(const page_t *page,
                                          mtr_t *mtr [[maybe_unused]]) {
  ut_ad(mtr != nullptr);
  return btr_page_get_prev(page);
}

/** Sets the previous index page field. */
static inline void btr_page_set_prev(
    page_t *page,             /*!< in: index page */
    page_zip_des_t *page_zip, /*!< in: compressed page whose uncompressed
                             part will be updated, or NULL */
    page_no_t prev,           /*!< in: previous page number */
    mtr_t *mtr)               /*!< in: mini-transaction handle */
{
  ut_ad(page != nullptr);
  ut_ad(mtr != nullptr);

  if (page_zip) {
    mach_write_to_4(page + FIL_PAGE_PREV, prev);
    page_zip_write_header(page_zip, page + FIL_PAGE_PREV, 4, mtr);
  } else {
    mlog_write_ulint(page + FIL_PAGE_PREV, prev, MLOG_4BYTES, mtr);
  }
}

static inline page_no_t btr_node_ptr_get_child_page_no(const rec_t *rec,
                                                       const ulint *offsets) {
  const byte *field;
  ulint len;
  page_no_t page_no;

  ut_ad(!rec_offs_comp(offsets) || rec_get_node_ptr_flag(rec));

  /* The child address is in the last field */
  field = rec_get_nth_field(nullptr, rec, offsets,
                            rec_offs_n_fields(offsets) - 1, &len);

  ut_ad(len == 4);

  page_no = mach_read_from_4(field);
  ut_ad(page_no > 1);

  return (page_no);
}

/** Check if the given page is first page on level.
@param[in]  page  Btree page
@return true if it is first page */
static inline bool btr_is_first_page_on_level(const page_t *page) {
  return (btr_page_get_prev(page) == FIL_NULL);
}

#ifndef UNIV_HOTBACKUP
/** Releases the latches on a leaf page and bufferunfixes it. */
static inline void btr_leaf_page_release(
    buf_block_t *block, /*!< in: buffer block */
    ulint latch_mode,   /*!< in: BTR_SEARCH_LEAF or
                        BTR_MODIFY_LEAF */
    mtr_t *mtr)         /*!< in: mtr */
{
  ut_ad(latch_mode == BTR_SEARCH_LEAF || latch_mode == BTR_MODIFY_LEAF ||
        latch_mode == BTR_NO_LATCHES);

  ut_ad(!mtr_memo_contains(mtr, block, MTR_MEMO_MODIFY));

  ulint mode;
  switch (latch_mode) {
    case BTR_SEARCH_LEAF:
      mode = MTR_MEMO_PAGE_S_FIX;
      break;
    case BTR_MODIFY_LEAF:
      mode = MTR_MEMO_PAGE_X_FIX;
      break;
    case BTR_NO_LATCHES:
      mode = MTR_MEMO_BUF_FIX;
      break;
    default:
      ut_error;
  }

  mtr->memo_release(block, mode);
}

#endif /* !UNIV_HOTBACKUP */
